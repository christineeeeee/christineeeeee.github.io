<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Package on Christine&#39;s Shattered Life</title>
    <link>https://christineeeeee.com/tags/package/</link>
    <description>Recent content in Package on Christine&#39;s Shattered Life</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Jun 2020 11:29:00 +0000</lastBuildDate>
    
	<atom:link href="https://christineeeeee.com/tags/package/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Notes on HDF5 Computation in Python (Updating)</title>
      <link>https://christineeeeee.com/posts/hdf5_intro/</link>
      <pubDate>Mon, 15 Jun 2020 11:29:00 +0000</pubDate>
      
      <guid>https://christineeeeee.com/posts/hdf5_intro/</guid>
      <description>Introduction This post is my personal notes on the application of HDF5 in Python.
As we all know, an HDF5 file contains two kinds of objects: groups and datasets. Groups are folder-like containers which hold all the datasets. Every HDF5 file is a root group and its name is &amp;lsquo;/&#39;. Datasets are arry-like containers of data.
As for datasets, every dataset could be split into two parts: raw data values and metadata.</description>
    </item>
    
    <item>
      <title>Flair - A Pretrained NLP Sentiment Analysis Tool</title>
      <link>https://christineeeeee.com/posts/nlp_sentiment_tool/</link>
      <pubDate>Sun, 10 May 2020 09:20:58 +0000</pubDate>
      
      <guid>https://christineeeeee.com/posts/nlp_sentiment_tool/</guid>
      <description>NLP(Natural Language Processing) includes sentiment analysis. Trained sentiment analysis includes machine learning, which is of course more accurate. For beginners who just stepped into this field, getting to know some pretrained sentiment analysis tools may also be a good choice. Here, I want to introduce a package I used to analyze sentiment. It&amp;rsquo;s called flair.
Flair&amp;rsquo;s mechanism is simple. It contains a powerful library which allows users to use and combine different word and document embeddings.</description>
    </item>
    
    <item>
      <title>Twint - A Twitter Scaping Tool</title>
      <link>https://christineeeeee.com/posts/twint/</link>
      <pubDate>Mon, 04 May 2020 17:16:00 +0000</pubDate>
      
      <guid>https://christineeeeee.com/posts/twint/</guid>
      <description>Recently I&amp;rsquo;ve been working on a python project about a twitter sentiment trading strategy(which will be introduced in my following posts), which requires a large load of tweets. While collecting data on Twitter, I found out that usual data crawling doesn&amp;rsquo;t work here since there&amp;rsquo;s limitation of Twitter&amp;rsquo;s API which only allows us to scrap at most last 3200 Tweets. This post introduces a really interesting and useful python package I found out which could be used to collect data without authentication, API and limitations.</description>
    </item>
    
  </channel>
</rss>